{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import timeit\n",
    "from pickle import dump\n",
    "\n",
    "# NLP imports\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#scikit learn imports\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, ParameterGrid\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['disaster_resp']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///DisasterResponse.db')\n",
    "\n",
    "# see table names to verify correct import to db\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe using table in db\n",
    "df = pd.read_sql_table('disaster_resp',engine) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into dependent and independent variables\n",
    "X = df['message']\n",
    "\n",
    "# target variable is all columns that have category data\n",
    "Y = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # normalize: lowercase and remove punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    # tokenize using words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # remove stop words\n",
    "    tokens = [t for t in tokens if t not in stopwords.words(\"english\")]\n",
    "    \n",
    "    #lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_tokens = [lemmatizer.lemmatize(tok).strip() for tok in tokens]\n",
    "    \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May need to download punkt package.\n",
    "# Uncomment below if needed\n",
    "\n",
    "#import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ETL, determined a column has a single label. Used randomforest classifier\n",
    "# since it can handle single labels\n",
    "# in MultiOutputClassifier, 'n-jobs = -1' means using all processors\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test data.\n",
    "# set random state for reproducibility \n",
    "# split into dependent and independent variables\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = .30, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (in seconds):  233.68115570000373\n"
     ]
    }
   ],
   "source": [
    "# train classifier using training data\n",
    "# if want to supress warnings, uncomment next line\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "start = timeit.default_timer()\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Training time (in seconds): ', stop - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "Y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should use F1 scores to assess the models. This is because f1 scores is more appropriate metric for unbalanced data, which is the case with this dataset. \n",
    "\n",
    "There are four possible choices with our dataset for f1 scores:\n",
    " 1. __Micro__: Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "\n",
    " 2. __Macro__: Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "\n",
    " 3. __Weighted__: Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall.\n",
    "\n",
    " 4. __Samples__: Calculate metrics for each instance, and find their average (only meaningful for multilabel classification where this differs from accuracy_score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.5944503197864733\n",
      "Macro F1 Score: 0.23056060745281387\n",
      "Weighted F1 Score: 0.5286867606863018\n",
      "Samples F1 Score: 0.4647858210861778\n"
     ]
    }
   ],
   "source": [
    "# get f1 score for this model since it is using imbalanced ata\n",
    "print('Micro F1 Score: ' + str(f1_score(y_test, Y_pred, average = 'micro')))\n",
    "print('Macro F1 Score: ' + str(f1_score(y_test, Y_pred, average = 'macro')))\n",
    "print('Weighted F1 Score: ' + str(f1_score(y_test, Y_pred, average = 'weighted')))\n",
    "print('Samples F1 Score: ' + str(f1_score(y_test, Y_pred, average = 'samples')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.46      0.54      1928\n",
      "           1       0.84      0.92      0.88      5937\n",
      "\n",
      "    accuracy                           0.81      7865\n",
      "   macro avg       0.75      0.69      0.71      7865\n",
      "weighted avg       0.79      0.81      0.80      7865\n",
      "\n",
      "\n",
      "request:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93      6511\n",
      "           1       0.77      0.47      0.58      1354\n",
      "\n",
      "    accuracy                           0.88      7865\n",
      "   macro avg       0.83      0.72      0.76      7865\n",
      "weighted avg       0.88      0.88      0.87      7865\n",
      "\n",
      "\n",
      "offer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7832\n",
      "           1       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      1.00      0.99      7865\n",
      "\n",
      "\n",
      "aid_related:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80      4577\n",
      "           1       0.75      0.60      0.67      3288\n",
      "\n",
      "    accuracy                           0.75      7865\n",
      "   macro avg       0.75      0.73      0.73      7865\n",
      "weighted avg       0.75      0.75      0.74      7865\n",
      "\n",
      "\n",
      "medical_help:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96      7199\n",
      "           1       0.55      0.11      0.18       666\n",
      "\n",
      "    accuracy                           0.92      7865\n",
      "   macro avg       0.73      0.55      0.57      7865\n",
      "weighted avg       0.89      0.92      0.89      7865\n",
      "\n",
      "\n",
      "medical_products:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      7447\n",
      "           1       0.74      0.15      0.25       418\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.85      0.58      0.61      7865\n",
      "weighted avg       0.94      0.95      0.94      7865\n",
      "\n",
      "\n",
      "search_and_rescue:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      7657\n",
      "           1       0.40      0.02      0.04       208\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.69      0.51      0.51      7865\n",
      "weighted avg       0.96      0.97      0.96      7865\n",
      "\n",
      "\n",
      "security:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7728\n",
      "           1       0.33      0.01      0.01       137\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.66      0.50      0.50      7865\n",
      "weighted avg       0.97      0.98      0.97      7865\n",
      "\n",
      "\n",
      "military:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      7636\n",
      "           1       0.46      0.07      0.13       229\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.72      0.54      0.56      7865\n",
      "weighted avg       0.96      0.97      0.96      7865\n",
      "\n",
      "\n",
      "child_alone:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7865\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       1.00      1.00      1.00      7865\n",
      "weighted avg       1.00      1.00      1.00      7865\n",
      "\n",
      "\n",
      "water:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7353\n",
      "           1       0.83      0.31      0.45       512\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.89      0.65      0.71      7865\n",
      "weighted avg       0.95      0.95      0.94      7865\n",
      "\n",
      "\n",
      "food:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      6977\n",
      "           1       0.83      0.43      0.56       888\n",
      "\n",
      "    accuracy                           0.93      7865\n",
      "   macro avg       0.88      0.71      0.76      7865\n",
      "weighted avg       0.92      0.93      0.91      7865\n",
      "\n",
      "\n",
      "shelter:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      7161\n",
      "           1       0.78      0.26      0.39       704\n",
      "\n",
      "    accuracy                           0.93      7865\n",
      "   macro avg       0.86      0.63      0.68      7865\n",
      "weighted avg       0.92      0.93      0.91      7865\n",
      "\n",
      "\n",
      "clothing:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7746\n",
      "           1       0.60      0.08      0.13       119\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.79      0.54      0.56      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "\n",
      "money:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7699\n",
      "           1       0.33      0.01      0.02       166\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.66      0.51      0.51      7865\n",
      "weighted avg       0.97      0.98      0.97      7865\n",
      "\n",
      "\n",
      "missing_people:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7770\n",
      "           1       1.00      0.02      0.04        95\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.99      0.51      0.52      7865\n",
      "weighted avg       0.99      0.99      0.98      7865\n",
      "\n",
      "\n",
      "refugees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      7602\n",
      "           1       0.73      0.04      0.08       263\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.85      0.52      0.53      7865\n",
      "weighted avg       0.96      0.97      0.95      7865\n",
      "\n",
      "\n",
      "death:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7530\n",
      "           1       0.72      0.18      0.28       335\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.84      0.59      0.63      7865\n",
      "weighted avg       0.95      0.96      0.95      7865\n",
      "\n",
      "\n",
      "other_aid:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93      6786\n",
      "           1       0.54      0.06      0.11      1079\n",
      "\n",
      "    accuracy                           0.86      7865\n",
      "   macro avg       0.71      0.53      0.52      7865\n",
      "weighted avg       0.82      0.86      0.81      7865\n",
      "\n",
      "\n",
      "infrastructure_related:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      7355\n",
      "           1       0.00      0.00      0.00       510\n",
      "\n",
      "    accuracy                           0.93      7865\n",
      "   macro avg       0.47      0.50      0.48      7865\n",
      "weighted avg       0.87      0.93      0.90      7865\n",
      "\n",
      "\n",
      "transport:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7509\n",
      "           1       0.74      0.08      0.15       356\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.85      0.54      0.56      7865\n",
      "weighted avg       0.95      0.96      0.94      7865\n",
      "\n",
      "\n",
      "buildings:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7438\n",
      "           1       0.79      0.11      0.19       427\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.87      0.55      0.58      7865\n",
      "weighted avg       0.94      0.95      0.93      7865\n",
      "\n",
      "\n",
      "electricity:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7705\n",
      "           1       0.62      0.06      0.11       160\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.80      0.53      0.55      7865\n",
      "weighted avg       0.97      0.98      0.97      7865\n",
      "\n",
      "\n",
      "tools:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7811\n",
      "           1       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      0.99      0.99      7865\n",
      "\n",
      "\n",
      "hospitals:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7785\n",
      "           1       0.50      0.01      0.02        80\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.74      0.51      0.51      7865\n",
      "weighted avg       0.98      0.99      0.99      7865\n",
      "\n",
      "\n",
      "shops:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7830\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      1.00      0.99      7865\n",
      "\n",
      "\n",
      "aid_centers:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7772\n",
      "           1       0.00      0.00      0.00        93\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "\n",
      "other_infrastructure:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7517\n",
      "           1       0.11      0.00      0.01       348\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.53      0.50      0.49      7865\n",
      "weighted avg       0.92      0.95      0.93      7865\n",
      "\n",
      "\n",
      "weather_related:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.90      5697\n",
      "           1       0.84      0.58      0.69      2168\n",
      "\n",
      "    accuracy                           0.85      7865\n",
      "   macro avg       0.85      0.77      0.80      7865\n",
      "weighted avg       0.85      0.85      0.84      7865\n",
      "\n",
      "\n",
      "floods:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.96      7212\n",
      "           1       0.84      0.24      0.37       653\n",
      "\n",
      "    accuracy                           0.93      7865\n",
      "   macro avg       0.89      0.62      0.67      7865\n",
      "weighted avg       0.93      0.93      0.92      7865\n",
      "\n",
      "\n",
      "storm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      7118\n",
      "           1       0.75      0.35      0.47       747\n",
      "\n",
      "    accuracy                           0.93      7865\n",
      "   macro avg       0.84      0.67      0.72      7865\n",
      "weighted avg       0.92      0.93      0.91      7865\n",
      "\n",
      "\n",
      "fire:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7769\n",
      "           1       0.50      0.02      0.04        96\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.74      0.51      0.52      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "\n",
      "earthquake:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      7148\n",
      "           1       0.87      0.62      0.72       717\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.92      0.81      0.85      7865\n",
      "weighted avg       0.95      0.96      0.95      7865\n",
      "\n",
      "\n",
      "cold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7720\n",
      "           1       0.68      0.16      0.26       145\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.83      0.58      0.62      7865\n",
      "weighted avg       0.98      0.98      0.98      7865\n",
      "\n",
      "\n",
      "other_weather:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7459\n",
      "           1       0.21      0.01      0.02       406\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.58      0.50      0.50      7865\n",
      "weighted avg       0.91      0.95      0.92      7865\n",
      "\n",
      "\n",
      "direct_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91      6304\n",
      "           1       0.72      0.31      0.44      1561\n",
      "\n",
      "    accuracy                           0.84      7865\n",
      "   macro avg       0.78      0.64      0.67      7865\n",
      "weighted avg       0.82      0.84      0.81      7865\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scoring the model, and seeing scores for each columns classification\n",
    "# the data we are using is imbalanced, so should use F1 score\n",
    "# will still look at other metrics\n",
    "\n",
    "column_list = list(Y.columns)\n",
    "for i in column_list:\n",
    "    y_true = y_test.to_numpy()[:,column_list.index(i)]\n",
    "    y_pred = Y_pred[:,column_list.index(i)]\n",
    "    print(column_list[column_list.index(i)]+ ':')\n",
    "    print(classification_report(y_true, y_pred) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf__estimator__bootstrap',\n",
       " 'clf__estimator__class_weight',\n",
       " 'clf__estimator__criterion',\n",
       " 'clf__estimator__max_depth',\n",
       " 'clf__estimator__max_features',\n",
       " 'clf__estimator__max_leaf_nodes',\n",
       " 'clf__estimator__min_impurity_decrease',\n",
       " 'clf__estimator__min_impurity_split',\n",
       " 'clf__estimator__min_samples_leaf',\n",
       " 'clf__estimator__min_samples_split',\n",
       " 'clf__estimator__min_weight_fraction_leaf',\n",
       " 'clf__estimator__n_estimators',\n",
       " 'clf__estimator__n_jobs',\n",
       " 'clf__estimator__oob_score',\n",
       " 'clf__estimator__random_state',\n",
       " 'clf__estimator__verbose',\n",
       " 'clf__estimator__warm_start',\n",
       " 'clf__estimator',\n",
       " 'clf__n_jobs']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to see all estimators, use the following:\n",
    "#pipeline.get_params().keys()\n",
    "\n",
    "# make the list more tidy to only see parameters for the classifier\n",
    "# iterate through dictionary keys to find parameters for the random forest classifier,\n",
    "# which have clf as the first three letters in the parameter namme\n",
    "[i for i in list(pipeline.get_params().keys()) if i.startswith('clf_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make set of parameter values to test in GridSearchCV\n",
    "params = {  'clf__estimator__bootstrap': [True, False],\n",
    "            'clf__estimator__n_estimators': [5,10]#, \n",
    "            #'clf__estimator__max_features': ['log2', 'sqrt','auto'],\n",
    "            #'clf__estimator__criterion': ['entropy', 'gini'], \n",
    "            #'clf__estimator__max_depth': [2, 3, 5, 10], \n",
    "            #'clf__estimator__min_samples_split': [2, 3, 5],\n",
    "            #'clf__estimator__min_samples_leaf': [1,5,8] \n",
    "         }\n",
    "\n",
    "random_forest_v1 = GridSearchCV(pipeline, param_grid=params, scoring='precision_samples', cv = None, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (in seconds):  937.4391565000042\n"
     ]
    }
   ],
   "source": [
    "# train model and measure how long this takes\n",
    "start = timeit.default_timer()\n",
    "\n",
    "random_forest_v1.fit(X_train, y_train)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Training time (in seconds): ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation time (in seconds):  48.965215199998056\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "Y_pred_rf1 = random_forest_v1.predict(X_test)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Validation time (in seconds): ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVERALL F-SCORES: \n",
      "Micro F1 Score: 0.6095441985511938\n",
      "Macro F1 Score: 0.23659088821858296\n",
      "Weighted F1 Score: 0.5413497084558296\n",
      "Samples F1 Score: 0.47606899887683196\n",
      "related:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.46      0.54      1928\n",
      "           1       0.84      0.92      0.88      5937\n",
      "\n",
      "    accuracy                           0.81      7865\n",
      "   macro avg       0.75      0.69      0.71      7865\n",
      "weighted avg       0.80      0.81      0.80      7865\n",
      "\n",
      "\n",
      "request:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      6511\n",
      "           1       0.78      0.44      0.56      1354\n",
      "\n",
      "    accuracy                           0.88      7865\n",
      "   macro avg       0.84      0.71      0.75      7865\n",
      "weighted avg       0.87      0.88      0.87      7865\n",
      "\n",
      "\n",
      "offer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7832\n",
      "           1       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      1.00      0.99      7865\n",
      "\n",
      "\n",
      "aid_related:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80      4577\n",
      "           1       0.76      0.60      0.67      3288\n",
      "\n",
      "    accuracy                           0.75      7865\n",
      "   macro avg       0.75      0.73      0.74      7865\n",
      "weighted avg       0.75      0.75      0.75      7865\n",
      "\n",
      "\n",
      "medical_help:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      7199\n",
      "           1       0.58      0.07      0.13       666\n",
      "\n",
      "    accuracy                           0.92      7865\n",
      "   macro avg       0.75      0.53      0.54      7865\n",
      "weighted avg       0.89      0.92      0.89      7865\n",
      "\n",
      "\n",
      "medical_products:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7447\n",
      "           1       0.74      0.10      0.17       418\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.85      0.55      0.57      7865\n",
      "weighted avg       0.94      0.95      0.93      7865\n",
      "\n",
      "\n",
      "search_and_rescue:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      7657\n",
      "           1       0.44      0.03      0.06       208\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.71      0.52      0.52      7865\n",
      "weighted avg       0.96      0.97      0.96      7865\n",
      "\n",
      "\n",
      "security:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7728\n",
      "           1       0.33      0.01      0.03       137\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.66      0.51      0.51      7865\n",
      "weighted avg       0.97      0.98      0.97      7865\n",
      "\n",
      "\n",
      "military:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      7636\n",
      "           1       0.51      0.08      0.14       229\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.74      0.54      0.56      7865\n",
      "weighted avg       0.96      0.97      0.96      7865\n",
      "\n",
      "\n",
      "child_alone:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7865\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       1.00      1.00      1.00      7865\n",
      "weighted avg       1.00      1.00      1.00      7865\n",
      "\n",
      "\n",
      "water:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7353\n",
      "           1       0.82      0.28      0.41       512\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.89      0.64      0.69      7865\n",
      "weighted avg       0.94      0.95      0.94      7865\n",
      "\n",
      "\n",
      "food:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      6977\n",
      "           1       0.82      0.58      0.68       888\n",
      "\n",
      "    accuracy                           0.94      7865\n",
      "   macro avg       0.88      0.78      0.82      7865\n",
      "weighted avg       0.93      0.94      0.93      7865\n",
      "\n",
      "\n",
      "shelter:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      7161\n",
      "           1       0.78      0.34      0.47       704\n",
      "\n",
      "    accuracy                           0.93      7865\n",
      "   macro avg       0.86      0.66      0.72      7865\n",
      "weighted avg       0.92      0.93      0.92      7865\n",
      "\n",
      "\n",
      "clothing:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7746\n",
      "           1       0.79      0.09      0.17       119\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.89      0.55      0.58      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "\n",
      "money:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7699\n",
      "           1       0.67      0.02      0.05       166\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.82      0.51      0.52      7865\n",
      "weighted avg       0.97      0.98      0.97      7865\n",
      "\n",
      "\n",
      "missing_people:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7770\n",
      "           1       0.00      0.00      0.00        95\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "\n",
      "refugees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      7602\n",
      "           1       0.52      0.05      0.08       263\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.74      0.52      0.53      7865\n",
      "weighted avg       0.95      0.97      0.95      7865\n",
      "\n",
      "\n",
      "death:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7530\n",
      "           1       0.78      0.14      0.24       335\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.87      0.57      0.61      7865\n",
      "weighted avg       0.96      0.96      0.95      7865\n",
      "\n",
      "\n",
      "other_aid:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93      6786\n",
      "           1       0.46      0.05      0.08      1079\n",
      "\n",
      "    accuracy                           0.86      7865\n",
      "   macro avg       0.66      0.52      0.50      7865\n",
      "weighted avg       0.81      0.86      0.81      7865\n",
      "\n",
      "\n",
      "infrastructure_related:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      7355\n",
      "           1       0.00      0.00      0.00       510\n",
      "\n",
      "    accuracy                           0.93      7865\n",
      "   macro avg       0.47      0.50      0.48      7865\n",
      "weighted avg       0.87      0.93      0.90      7865\n",
      "\n",
      "\n",
      "transport:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7509\n",
      "           1       0.59      0.09      0.16       356\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.78      0.54      0.57      7865\n",
      "weighted avg       0.94      0.96      0.94      7865\n",
      "\n",
      "\n",
      "buildings:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7438\n",
      "           1       0.76      0.06      0.11       427\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.86      0.53      0.54      7865\n",
      "weighted avg       0.94      0.95      0.93      7865\n",
      "\n",
      "\n",
      "electricity:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7705\n",
      "           1       0.60      0.02      0.04       160\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.79      0.51      0.51      7865\n",
      "weighted avg       0.97      0.98      0.97      7865\n",
      "\n",
      "\n",
      "tools:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7811\n",
      "           1       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      0.99      0.99      7865\n",
      "\n",
      "\n",
      "hospitals:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7785\n",
      "           1       0.50      0.01      0.02        80\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.74      0.51      0.51      7865\n",
      "weighted avg       0.98      0.99      0.99      7865\n",
      "\n",
      "\n",
      "shops:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7830\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      1.00      0.99      7865\n",
      "\n",
      "\n",
      "aid_centers:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7772\n",
      "           1       0.00      0.00      0.00        93\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "\n",
      "other_infrastructure:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7517\n",
      "           1       0.00      0.00      0.00       348\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.48      0.50      0.49      7865\n",
      "weighted avg       0.91      0.96      0.93      7865\n",
      "\n",
      "\n",
      "weather_related:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      5697\n",
      "           1       0.83      0.63      0.72      2168\n",
      "\n",
      "    accuracy                           0.86      7865\n",
      "   macro avg       0.85      0.79      0.81      7865\n",
      "weighted avg       0.86      0.86      0.86      7865\n",
      "\n",
      "\n",
      "floods:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7212\n",
      "           1       0.88      0.36      0.51       653\n",
      "\n",
      "    accuracy                           0.94      7865\n",
      "   macro avg       0.91      0.68      0.74      7865\n",
      "weighted avg       0.94      0.94      0.93      7865\n",
      "\n",
      "\n",
      "storm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      7118\n",
      "           1       0.78      0.47      0.58       747\n",
      "\n",
      "    accuracy                           0.94      7865\n",
      "   macro avg       0.86      0.73      0.77      7865\n",
      "weighted avg       0.93      0.94      0.93      7865\n",
      "\n",
      "\n",
      "fire:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7769\n",
      "           1       0.00      0.00      0.00        96\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "\n",
      "earthquake:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      7148\n",
      "           1       0.89      0.70      0.78       717\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.93      0.85      0.88      7865\n",
      "weighted avg       0.96      0.97      0.96      7865\n",
      "\n",
      "\n",
      "cold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7720\n",
      "           1       0.72      0.12      0.21       145\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.85      0.56      0.60      7865\n",
      "weighted avg       0.98      0.98      0.98      7865\n",
      "\n",
      "\n",
      "other_weather:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7459\n",
      "           1       0.51      0.06      0.11       406\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.73      0.53      0.54      7865\n",
      "weighted avg       0.93      0.95      0.93      7865\n",
      "\n",
      "\n",
      "direct_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.98      0.91      6304\n",
      "           1       0.76      0.31      0.44      1561\n",
      "\n",
      "    accuracy                           0.84      7865\n",
      "   macro avg       0.80      0.64      0.67      7865\n",
      "weighted avg       0.83      0.84      0.82      7865\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see scores for the model\n",
    "print('OVERALL F-SCORES: ')\n",
    "print('Micro F1 Score: ' + str(f1_score(y_test, Y_pred_rf1, average = 'micro')))\n",
    "print('Macro F1 Score: ' + str(f1_score(y_test, Y_pred_rf1, average = 'macro')))\n",
    "print('Weighted F1 Score: ' + str(f1_score(y_test, Y_pred_rf1, average = 'weighted')))\n",
    "print('Samples F1 Score: ' + str(f1_score(y_test, Y_pred_rf1, average = 'samples')))\n",
    "\n",
    "for i in column_list:\n",
    "    y_true = y_test.to_numpy()[:,column_list.index(i)]\n",
    "    y_pred = Y_pred_rf1[:,column_list.index(i)]\n",
    "    print(column_list[column_list.index(i)]+ ':')\n",
    "    #text = [column_list[i], 'not']\n",
    "    print(classification_report(y_true, y_pred) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performed worse. Will try one more time to find better parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make set of parameter values to test in GridSearchCV\n",
    "params = {  'clf__estimator__bootstrap': [True, False],\n",
    "            'clf__estimator__n_estimators': [10, 20], \n",
    "            # for max features, 'auto' and 'sqrt' are the same\n",
    "            'clf__estimator__max_features': ['log2','auto'],\n",
    "            'clf__estimator__criterion': ['entropy', 'gini'], \n",
    "            #'clf__estimator__max_depth': [2, 3, 5, 10], \n",
    "            #'clf__estimator__min_samples_split': [2, 3, 5],\n",
    "            #'clf__estimator__min_samples_leaf': [1,5,8] \n",
    "         }\n",
    "\n",
    "random_forest_v2 = GridSearchCV(pipeline, param_grid=params, scoring='precision_samples', cv = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (in seconds):  7171.3076019\n"
     ]
    }
   ],
   "source": [
    "# train model and measure how long this takes\n",
    "start = timeit.default_timer()\n",
    "\n",
    "random_forest_v2.fit(X_train, y_train)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Training time (in seconds): ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (in seconds):  55.39805679999699\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "Y_pred_rf2 = random_forest_v2.predict(X_test)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Training time (in seconds): ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize at...\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                                        class_weight=None,\n",
       "                                                                        criterion='gini',\n",
       "                                                                        max_depth=None,\n",
       "                                                                        max_features='log2',\n",
       "                                                                        max_leaf_nodes=None,\n",
       "                                                                        min_impurity_decrease=0.0,\n",
       "                                                                        min_impurity_split=None,\n",
       "                                                                        min_samples_leaf=1,\n",
       "                                                                        min_samples_split=2,\n",
       "                                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                                        n_estimators=20,\n",
       "                                                                        n_jobs=None,\n",
       "                                                                        oob_score=False,\n",
       "                                                                        random_state=None,\n",
       "                                                                        verbose=0,\n",
       "                                                                        warm_start=False),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_v2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVERALL F-SCORES: \n",
      "Micro F1 Score: 0.5353935765714748\n",
      "Macro F1 Score: 0.13866263895875613\n",
      "Weighted F1 Score: 0.44468146400480496\n",
      "Samples F1 Score: 0.45005375506355255\n",
      "related:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.38      0.49      1928\n",
      "           1       0.82      0.95      0.88      5937\n",
      "\n",
      "    accuracy                           0.81      7865\n",
      "   macro avg       0.77      0.66      0.69      7865\n",
      "weighted avg       0.80      0.81      0.79      7865\n",
      "\n",
      "\n",
      "request:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93      6511\n",
      "           1       0.84      0.37      0.51      1354\n",
      "\n",
      "    accuracy                           0.88      7865\n",
      "   macro avg       0.86      0.68      0.72      7865\n",
      "weighted avg       0.87      0.88      0.86      7865\n",
      "\n",
      "\n",
      "offer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7832\n",
      "           1       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      1.00      0.99      7865\n",
      "\n",
      "\n",
      "aid_related:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.90      0.80      4577\n",
      "           1       0.78      0.51      0.62      3288\n",
      "\n",
      "    accuracy                           0.74      7865\n",
      "   macro avg       0.75      0.70      0.71      7865\n",
      "weighted avg       0.74      0.74      0.72      7865\n",
      "\n",
      "\n",
      "medical_help:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      7199\n",
      "           1       0.44      0.02      0.03       666\n",
      "\n",
      "    accuracy                           0.91      7865\n",
      "   macro avg       0.68      0.51      0.49      7865\n",
      "weighted avg       0.88      0.91      0.88      7865\n",
      "\n",
      "\n",
      "medical_products:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7447\n",
      "           1       0.82      0.03      0.06       418\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.89      0.52      0.52      7865\n",
      "weighted avg       0.94      0.95      0.93      7865\n",
      "\n",
      "\n",
      "search_and_rescue:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      7657\n",
      "           1       0.00      0.00      0.00       208\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.49      0.50      0.49      7865\n",
      "weighted avg       0.95      0.97      0.96      7865\n",
      "\n",
      "\n",
      "security:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7728\n",
      "           1       0.50      0.01      0.01       137\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.74      0.50      0.50      7865\n",
      "weighted avg       0.97      0.98      0.97      7865\n",
      "\n",
      "\n",
      "military:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      7636\n",
      "           1       0.67      0.01      0.02       229\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.82      0.50      0.50      7865\n",
      "weighted avg       0.96      0.97      0.96      7865\n",
      "\n",
      "\n",
      "child_alone:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7865\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       1.00      1.00      1.00      7865\n",
      "weighted avg       1.00      1.00      1.00      7865\n",
      "\n",
      "\n",
      "water:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7353\n",
      "           1       0.91      0.17      0.28       512\n",
      "\n",
      "    accuracy                           0.94      7865\n",
      "   macro avg       0.93      0.58      0.63      7865\n",
      "weighted avg       0.94      0.94      0.93      7865\n",
      "\n",
      "\n",
      "food:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      6977\n",
      "           1       0.89      0.22      0.35       888\n",
      "\n",
      "    accuracy                           0.91      7865\n",
      "   macro avg       0.90      0.61      0.65      7865\n",
      "weighted avg       0.91      0.91      0.88      7865\n",
      "\n",
      "\n",
      "shelter:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      7161\n",
      "           1       0.92      0.08      0.15       704\n",
      "\n",
      "    accuracy                           0.92      7865\n",
      "   macro avg       0.92      0.54      0.55      7865\n",
      "weighted avg       0.92      0.92      0.88      7865\n",
      "\n",
      "\n",
      "clothing:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7746\n",
      "           1       1.00      0.03      0.07       119\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.99      0.52      0.53      7865\n",
      "weighted avg       0.99      0.99      0.98      7865\n",
      "\n",
      "\n",
      "money:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7699\n",
      "           1       1.00      0.02      0.04       166\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.99      0.51      0.51      7865\n",
      "weighted avg       0.98      0.98      0.97      7865\n",
      "\n",
      "\n",
      "missing_people:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7770\n",
      "           1       0.00      0.00      0.00        95\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "\n",
      "refugees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      7602\n",
      "           1       0.00      0.00      0.00       263\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.48      0.50      0.49      7865\n",
      "weighted avg       0.93      0.97      0.95      7865\n",
      "\n",
      "\n",
      "death:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7530\n",
      "           1       0.73      0.02      0.05       335\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.84      0.51      0.51      7865\n",
      "weighted avg       0.95      0.96      0.94      7865\n",
      "\n",
      "\n",
      "other_aid:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93      6786\n",
      "           1       0.50      0.02      0.03      1079\n",
      "\n",
      "    accuracy                           0.86      7865\n",
      "   macro avg       0.68      0.51      0.48      7865\n",
      "weighted avg       0.81      0.86      0.80      7865\n",
      "\n",
      "\n",
      "infrastructure_related:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      7355\n",
      "           1       0.25      0.00      0.00       510\n",
      "\n",
      "    accuracy                           0.93      7865\n",
      "   macro avg       0.59      0.50      0.49      7865\n",
      "weighted avg       0.89      0.93      0.90      7865\n",
      "\n",
      "\n",
      "transport:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7509\n",
      "           1       0.67      0.01      0.02       356\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.81      0.51      0.50      7865\n",
      "weighted avg       0.94      0.95      0.93      7865\n",
      "\n",
      "\n",
      "buildings:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7438\n",
      "           1       0.80      0.01      0.02       427\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.87      0.50      0.50      7865\n",
      "weighted avg       0.94      0.95      0.92      7865\n",
      "\n",
      "\n",
      "electricity:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7705\n",
      "           1       0.00      0.00      0.00       160\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.49      0.50      0.49      7865\n",
      "weighted avg       0.96      0.98      0.97      7865\n",
      "\n",
      "\n",
      "tools:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7811\n",
      "           1       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      0.99      0.99      7865\n",
      "\n",
      "\n",
      "hospitals:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7785\n",
      "           1       0.00      0.00      0.00        80\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "\n",
      "shops:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7830\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      1.00      0.99      7865\n",
      "\n",
      "\n",
      "aid_centers:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7772\n",
      "           1       0.00      0.00      0.00        93\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "\n",
      "other_infrastructure:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7517\n",
      "           1       0.00      0.00      0.00       348\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.48      0.50      0.49      7865\n",
      "weighted avg       0.91      0.96      0.93      7865\n",
      "\n",
      "\n",
      "weather_related:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.89      5697\n",
      "           1       0.86      0.42      0.56      2168\n",
      "\n",
      "    accuracy                           0.82      7865\n",
      "   macro avg       0.84      0.69      0.72      7865\n",
      "weighted avg       0.83      0.82      0.80      7865\n",
      "\n",
      "\n",
      "floods:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      7212\n",
      "           1       0.92      0.07      0.13       653\n",
      "\n",
      "    accuracy                           0.92      7865\n",
      "   macro avg       0.92      0.54      0.55      7865\n",
      "weighted avg       0.92      0.92      0.89      7865\n",
      "\n",
      "\n",
      "storm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.95      7118\n",
      "           1       0.81      0.13      0.22       747\n",
      "\n",
      "    accuracy                           0.91      7865\n",
      "   macro avg       0.86      0.56      0.59      7865\n",
      "weighted avg       0.91      0.91      0.89      7865\n",
      "\n",
      "\n",
      "fire:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7769\n",
      "           1       0.00      0.00      0.00        96\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "\n",
      "earthquake:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      7148\n",
      "           1       0.90      0.32      0.48       717\n",
      "\n",
      "    accuracy                           0.94      7865\n",
      "   macro avg       0.92      0.66      0.72      7865\n",
      "weighted avg       0.93      0.94      0.92      7865\n",
      "\n",
      "\n",
      "cold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7720\n",
      "           1       0.67      0.01      0.03       145\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.82      0.51      0.51      7865\n",
      "weighted avg       0.98      0.98      0.97      7865\n",
      "\n",
      "\n",
      "other_weather:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7459\n",
      "           1       0.67      0.01      0.02       406\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.81      0.50      0.50      7865\n",
      "weighted avg       0.93      0.95      0.92      7865\n",
      "\n",
      "\n",
      "direct_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91      6304\n",
      "           1       0.79      0.27      0.40      1561\n",
      "\n",
      "    accuracy                           0.84      7865\n",
      "   macro avg       0.82      0.63      0.66      7865\n",
      "weighted avg       0.83      0.84      0.81      7865\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see scores for the model\n",
    "print('OVERALL F-SCORES: ')\n",
    "print('Micro F1 Score: ' + str(f1_score(y_test, Y_pred_rf2, average = 'micro')))\n",
    "print('Macro F1 Score: ' + str(f1_score(y_test, Y_pred_rf2, average = 'macro')))\n",
    "print('Weighted F1 Score: ' + str(f1_score(y_test, Y_pred_rf2, average = 'weighted')))\n",
    "print('Samples F1 Score: ' + str(f1_score(y_test, Y_pred_rf2, average = 'samples')))\n",
    "\n",
    "for i in column_list:\n",
    "    y_true = y_test.to_numpy()[:,column_list.index(i)]\n",
    "    y_pred = Y_pred_rf2[:,column_list.index(i)]\n",
    "    print(column_list[column_list.index(i)]+ ':')\n",
    "    #text = [column_list[i], 'not']\n",
    "    print(classification_report(y_true, y_pred) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performed worse than both previous models\n",
    "Stick with original training, and try different classficaction algorithms later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame(columns = ['Model', 'F1 Score (Micro)', 'F1 Score (Weighted)', 'Training Time (Seconds)'])\n",
    "models = models.append({'Model': 'Random Forest', \n",
    "               'F1 Score (Micro)' : f1_score(y_test, Y_pred, average = 'micro'),\n",
    "               'F1 Score (Weighted)' : f1_score(y_test, Y_pred, average = 'weighted'),\n",
    "               'Training Time (Seconds)': 1149\n",
    "              }, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.5944503197864733\n",
      "Macro F1 Score: 0.23056060745281387\n",
      "Weighted F1 Score: 0.5286867606863018\n",
      "Samples F1 Score: 0.4647858210861778\n"
     ]
    }
   ],
   "source": [
    "# get f1 score for this model since it is using imbalanced ata\n",
    "print('Micro F1 Score: ' + str(f1_score(y_test, Y_pred, average = 'micro')))\n",
    "print('Macro F1 Score: ' + str(f1_score(y_test, Y_pred, average = 'macro')))\n",
    "print('Weighted F1 Score: ' + str(f1_score(y_test, Y_pred, average = 'weighted')))\n",
    "print('Samples F1 Score: ' + str(f1_score(y_test, Y_pred, average = 'samples')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF\n",
    "\n",
    "\n",
    "\n",
    "Trying a linear classifier with a stochastic gradient descent  training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the child_alone column since it only has 0's\n",
    "# and will not work in this classification algorithm\n",
    "df2 = df.drop('child_alone', axis = 1)\n",
    "\n",
    "X = df2['message']\n",
    "\n",
    "# target variable is all columns that have category data\n",
    "Y = df2.iloc[:,4:]\n",
    "\n",
    "# split filtered data since altered dataset\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, Y, test_size = .30, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (in seconds):  106.50824439999997\n",
      "Micro F1 Score: 0.6697575399172088\n",
      "Macro F1 Score: 0.32973251688510047\n",
      "Weighted F1 Score: 0.6073477961701148\n",
      "Samples F1 Score: 0.519043199937892\n"
     ]
    }
   ],
   "source": [
    "# make pipeline with SGD classifier\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(SGDClassifier()))\n",
    "])\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "pipeline2.fit(X_train2, y_train2)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Training time (in seconds): ', stop - start)\n",
    "\n",
    "Y_pred2 = pipeline2.predict(X_test2)\n",
    "\n",
    "\n",
    "# get f1 score for this model since it is using imbalanced ata\n",
    "print('Micro F1 Score: ' + str(f1_score(y_test2, Y_pred2, average = 'micro')))\n",
    "print('Macro F1 Score: ' + str(f1_score(y_test2, Y_pred2, average = 'macro')))\n",
    "print('Weighted F1 Score: ' + str(f1_score(y_test2, Y_pred2, average = 'weighted')))\n",
    "print('Samples F1 Score: ' + str(f1_score(y_test2, Y_pred2, average = 'samples')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = models.append({'Model': 'SGD', \n",
    "               'F1 Score (Micro)' : f1_score(y_test2, Y_pred2, average = 'micro'),\n",
    "               'F1 Score (Weighted)' : f1_score(y_test2, Y_pred2, average = 'weighted'),\n",
    "               'Training Time (Seconds)' : 154\n",
    "              }, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now trying a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (in seconds):  108.8156525000013\n",
      "Micro F1 Score: 0.6458867340523287\n",
      "Macro F1 Score: 0.2881896124660017\n",
      "Weighted F1 Score: 0.5854424461485186\n",
      "Samples F1 Score: 0.5071035672299045\n"
     ]
    }
   ],
   "source": [
    "pipeline3 = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(LogisticRegression()))\n",
    "])\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "pipeline3.fit(X_train2, y_train2)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Training time (in seconds): ', stop - start)\n",
    "\n",
    "Y_pred3 = pipeline3.predict(X_test2)\n",
    "\n",
    "# get f1 score for this model since it is using imbalanced ata\n",
    "print('Micro F1 Score: ' + str(f1_score(y_test2, Y_pred3, average = 'micro')))\n",
    "print('Macro F1 Score: ' + str(f1_score(y_test2, Y_pred3, average = 'macro')))\n",
    "print('Weighted F1 Score: ' + str(f1_score(y_test2, Y_pred3, average = 'weighted')))\n",
    "print('Samples F1 Score: ' + str(f1_score(y_test2, Y_pred3, average = 'samples')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = models.append({'Model': 'Logistic Regression', \n",
    "               'F1 Score (Micro)' : f1_score(y_test2, Y_pred3, average = 'micro'),\n",
    "               'F1 Score (Weighted)' : f1_score(y_test2, Y_pred3, average = 'weighted'),\n",
    "               'Training Time (Seconds)' : (stop-start)\n",
    "              }, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1 Score (Micro)</th>\n",
       "      <th>F1 Score (Weighted)</th>\n",
       "      <th>Training Time (Seconds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.594450</td>\n",
       "      <td>0.528687</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.669758</td>\n",
       "      <td>0.607348</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.645887</td>\n",
       "      <td>0.585442</td>\n",
       "      <td>108.816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  F1 Score (Micro)  F1 Score (Weighted)  \\\n",
       "0        Random Forest          0.594450             0.528687   \n",
       "1                  SGD          0.669758             0.607348   \n",
       "2  Logistic Regression          0.645887             0.585442   \n",
       "\n",
       "  Training Time (Seconds)  \n",
       "0                    1149  \n",
       "1                     154  \n",
       "2                 108.816  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference = 0.415\n"
     ]
    }
   ],
   "source": [
    "# Time difference between SGD and logistic regression\n",
    "print('Difference = ' + str(round((models.iloc[1,3] / models.iloc[2,3]) - 1, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SGD model had the best micro f1 score. Although the logistic regression model took less time to train, it wasn't much faster than the SGD model. Will use the SGD model for message classification application.\n",
    "\n",
    "However, this assignment requires implmenting GridSearchCV, so the best model using GridSearchCV needs to be used. I will use GridSearchCV with the SGD model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf__estimator__alpha',\n",
       " 'clf__estimator__average',\n",
       " 'clf__estimator__class_weight',\n",
       " 'clf__estimator__early_stopping',\n",
       " 'clf__estimator__epsilon',\n",
       " 'clf__estimator__eta0',\n",
       " 'clf__estimator__fit_intercept',\n",
       " 'clf__estimator__l1_ratio',\n",
       " 'clf__estimator__learning_rate',\n",
       " 'clf__estimator__loss',\n",
       " 'clf__estimator__max_iter',\n",
       " 'clf__estimator__n_iter_no_change',\n",
       " 'clf__estimator__n_jobs',\n",
       " 'clf__estimator__penalty',\n",
       " 'clf__estimator__power_t',\n",
       " 'clf__estimator__random_state',\n",
       " 'clf__estimator__shuffle',\n",
       " 'clf__estimator__tol',\n",
       " 'clf__estimator__validation_fraction',\n",
       " 'clf__estimator__verbose',\n",
       " 'clf__estimator__warm_start',\n",
       " 'clf__estimator',\n",
       " 'clf__n_jobs']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only get params for classifier\n",
    "[i for i in list(pipeline2.get_params().keys()) if i.startswith('clf_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    }
   ],
   "source": [
    "# make set of parameter values to test in GridSearchCV\n",
    "# only chose a few parameters\n",
    "params = {   #'clf__estimator__alpha',\n",
    "             #'clf__estimator__average': [True, False],\n",
    "             #'clf__estimator__class_weight',\n",
    "             #'clf__estimator__early_stopping' : [True, False],\n",
    "             #'clf__estimator__epsilon',\n",
    "             'clf__estimator__eta0': [0.01],\n",
    "             #'clf__estimator__fit_intercept': [True, False],\n",
    "             #'clf__estimator__l1_ratio',\n",
    "             'clf__estimator__learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "             'clf__estimator__loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', \\\n",
    "                              'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "             #'clf__estimator__max_iter',\n",
    "             #'clf__estimator__n_iter_no_change': [5, 10],\n",
    "             #'clf__estimator__n_jobs',\n",
    "             'clf__estimator__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "             #'clf__estimator__power_t',\n",
    "             'clf__estimator__random_state': [50]\n",
    "             #'clf__estimator__shuffle': [True, False],\n",
    "             #'clf__estimator__tol',\n",
    "             #'clf__estimator__validation_fraction',\n",
    "             #'clf__estimator__verbose',\n",
    "             #'clf__estimator__warm_start': [True, False]\n",
    "         }\n",
    "\n",
    "# size of grid\n",
    "pg = ParameterGrid(params)\n",
    "print(len(pg))\n",
    "\n",
    "sgd_grid = GridSearchCV(pipeline2, param_grid=params, scoring='precision_samples', cv = None, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (in seconds):  20240.4545716\n"
     ]
    }
   ],
   "source": [
    "# train model and measure how long this takes\n",
    "start = timeit.default_timer()\n",
    "\n",
    "sgd_grid.fit(X_train2, y_train2)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Training time (in seconds): ', stop - start)\n",
    "\n",
    "# 20,240 seconds (5.6 hours) for a grid size of 108 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize at...\n",
       "                 MultiOutputClassifier(estimator=SGDClassifier(alpha=0.0001,\n",
       "                                                               average=False,\n",
       "                                                               class_weight=None,\n",
       "                                                               early_stopping=False,\n",
       "                                                               epsilon=0.1,\n",
       "                                                               eta0=0.01,\n",
       "                                                               fit_intercept=True,\n",
       "                                                               l1_ratio=0.15,\n",
       "                                                               learning_rate='invscaling',\n",
       "                                                               loss='huber',\n",
       "                                                               max_iter=1000,\n",
       "                                                               n_iter_no_change=5,\n",
       "                                                               n_jobs=None,\n",
       "                                                               penalty='l1',\n",
       "                                                               power_t=0.5,\n",
       "                                                               random_state=50,\n",
       "                                                               shuffle=True,\n",
       "                                                               tol=0.001,\n",
       "                                                               validation_fraction=0.1,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation time (in seconds):  49.60978360000445\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "Y_pred_sgd_grid = sgd_grid.predict(X_test2)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Validation time (in seconds): ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVERALL F-SCORES: \n",
      "Micro F1 Score: 0.3927000356675782\n",
      "Macro F1 Score: 0.03439432261131815\n",
      "Weighted F1 Score: 0.24826468424956508\n",
      "Samples F1 Score: 0.40817995785946215\n",
      "related:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1928\n",
      "           1       0.75      1.00      0.86      5937\n",
      "\n",
      "    accuracy                           0.75      7865\n",
      "   macro avg       0.38      0.50      0.43      7865\n",
      "weighted avg       0.57      0.75      0.65      7865\n",
      "\n",
      "\n",
      "request:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91      6511\n",
      "           1       0.00      0.00      0.00      1354\n",
      "\n",
      "    accuracy                           0.83      7865\n",
      "   macro avg       0.41      0.50      0.45      7865\n",
      "weighted avg       0.69      0.83      0.75      7865\n",
      "\n",
      "\n",
      "offer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7832\n",
      "           1       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      1.00      0.99      7865\n",
      "\n",
      "\n",
      "aid_related:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.97      0.76      4577\n",
      "           1       0.84      0.20      0.32      3288\n",
      "\n",
      "    accuracy                           0.65      7865\n",
      "   macro avg       0.74      0.58      0.54      7865\n",
      "weighted avg       0.72      0.65      0.58      7865\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\regomoto\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "medical_help:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      7199\n",
      "           1       0.00      0.00      0.00       666\n",
      "\n",
      "    accuracy                           0.92      7865\n",
      "   macro avg       0.46      0.50      0.48      7865\n",
      "weighted avg       0.84      0.92      0.87      7865\n",
      "\n",
      "\n",
      "medical_products:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7447\n",
      "           1       0.00      0.00      0.00       418\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.47      0.50      0.49      7865\n",
      "weighted avg       0.90      0.95      0.92      7865\n",
      "\n",
      "\n",
      "search_and_rescue:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      7657\n",
      "           1       0.00      0.00      0.00       208\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.49      0.50      0.49      7865\n",
      "weighted avg       0.95      0.97      0.96      7865\n",
      "\n",
      "\n",
      "security:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7728\n",
      "           1       0.00      0.00      0.00       137\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.97      0.98      0.97      7865\n",
      "\n",
      "\n",
      "military:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      7636\n",
      "           1       0.00      0.00      0.00       229\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.49      0.50      0.49      7865\n",
      "weighted avg       0.94      0.97      0.96      7865\n",
      "\n",
      "\n",
      "water:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97      7353\n",
      "           1       0.00      0.00      0.00       512\n",
      "\n",
      "    accuracy                           0.93      7865\n",
      "   macro avg       0.47      0.50      0.48      7865\n",
      "weighted avg       0.87      0.93      0.90      7865\n",
      "\n",
      "\n",
      "food:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      6977\n",
      "           1       0.00      0.00      0.00       888\n",
      "\n",
      "    accuracy                           0.89      7865\n",
      "   macro avg       0.44      0.50      0.47      7865\n",
      "weighted avg       0.79      0.89      0.83      7865\n",
      "\n",
      "\n",
      "shelter:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      7161\n",
      "           1       0.00      0.00      0.00       704\n",
      "\n",
      "    accuracy                           0.91      7865\n",
      "   macro avg       0.46      0.50      0.48      7865\n",
      "weighted avg       0.83      0.91      0.87      7865\n",
      "\n",
      "\n",
      "clothing:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7746\n",
      "           1       0.00      0.00      0.00       119\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.97      0.98      0.98      7865\n",
      "\n",
      "\n",
      "money:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7699\n",
      "           1       0.00      0.00      0.00       166\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.49      0.50      0.49      7865\n",
      "weighted avg       0.96      0.98      0.97      7865\n",
      "\n",
      "\n",
      "missing_people:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7770\n",
      "           1       0.00      0.00      0.00        95\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "\n",
      "refugees:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      7602\n",
      "           1       0.00      0.00      0.00       263\n",
      "\n",
      "    accuracy                           0.97      7865\n",
      "   macro avg       0.48      0.50      0.49      7865\n",
      "weighted avg       0.93      0.97      0.95      7865\n",
      "\n",
      "\n",
      "death:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7530\n",
      "           1       0.00      0.00      0.00       335\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.48      0.50      0.49      7865\n",
      "weighted avg       0.92      0.96      0.94      7865\n",
      "\n",
      "\n",
      "other_aid:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93      6786\n",
      "           1       0.00      0.00      0.00      1079\n",
      "\n",
      "    accuracy                           0.86      7865\n",
      "   macro avg       0.43      0.50      0.46      7865\n",
      "weighted avg       0.74      0.86      0.80      7865\n",
      "\n",
      "\n",
      "infrastructure_related:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      7355\n",
      "           1       0.00      0.00      0.00       510\n",
      "\n",
      "    accuracy                           0.94      7865\n",
      "   macro avg       0.47      0.50      0.48      7865\n",
      "weighted avg       0.87      0.94      0.90      7865\n",
      "\n",
      "\n",
      "transport:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      7509\n",
      "           1       0.00      0.00      0.00       356\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.48      0.50      0.49      7865\n",
      "weighted avg       0.91      0.95      0.93      7865\n",
      "\n",
      "\n",
      "buildings:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7438\n",
      "           1       0.00      0.00      0.00       427\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.47      0.50      0.49      7865\n",
      "weighted avg       0.89      0.95      0.92      7865\n",
      "\n",
      "\n",
      "electricity:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7705\n",
      "           1       0.00      0.00      0.00       160\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.49      0.50      0.49      7865\n",
      "weighted avg       0.96      0.98      0.97      7865\n",
      "\n",
      "\n",
      "tools:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7811\n",
      "           1       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      0.99      0.99      7865\n",
      "\n",
      "\n",
      "hospitals:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7785\n",
      "           1       0.00      0.00      0.00        80\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "\n",
      "shops:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7830\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           1.00      7865\n",
      "   macro avg       0.50      0.50      0.50      7865\n",
      "weighted avg       0.99      1.00      0.99      7865\n",
      "\n",
      "\n",
      "aid_centers:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7772\n",
      "           1       0.00      0.00      0.00        93\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "\n",
      "other_infrastructure:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      7517\n",
      "           1       0.00      0.00      0.00       348\n",
      "\n",
      "    accuracy                           0.96      7865\n",
      "   macro avg       0.48      0.50      0.49      7865\n",
      "weighted avg       0.91      0.96      0.93      7865\n",
      "\n",
      "\n",
      "weather_related:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84      5697\n",
      "           1       0.90      0.01      0.02      2168\n",
      "\n",
      "    accuracy                           0.73      7865\n",
      "   macro avg       0.81      0.51      0.43      7865\n",
      "weighted avg       0.77      0.73      0.62      7865\n",
      "\n",
      "\n",
      "floods:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      7212\n",
      "           1       0.00      0.00      0.00       653\n",
      "\n",
      "    accuracy                           0.92      7865\n",
      "   macro avg       0.46      0.50      0.48      7865\n",
      "weighted avg       0.84      0.92      0.88      7865\n",
      "\n",
      "\n",
      "storm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      7118\n",
      "           1       0.00      0.00      0.00       747\n",
      "\n",
      "    accuracy                           0.91      7865\n",
      "   macro avg       0.45      0.50      0.48      7865\n",
      "weighted avg       0.82      0.91      0.86      7865\n",
      "\n",
      "\n",
      "fire:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7769\n",
      "           1       0.00      0.00      0.00        96\n",
      "\n",
      "    accuracy                           0.99      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.98      0.99      0.98      7865\n",
      "\n",
      "\n",
      "earthquake:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      7148\n",
      "           1       1.00      0.00      0.00       717\n",
      "\n",
      "    accuracy                           0.91      7865\n",
      "   macro avg       0.95      0.50      0.48      7865\n",
      "weighted avg       0.92      0.91      0.87      7865\n",
      "\n",
      "\n",
      "cold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      7720\n",
      "           1       0.00      0.00      0.00       145\n",
      "\n",
      "    accuracy                           0.98      7865\n",
      "   macro avg       0.49      0.50      0.50      7865\n",
      "weighted avg       0.96      0.98      0.97      7865\n",
      "\n",
      "\n",
      "other_weather:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      7459\n",
      "           1       0.00      0.00      0.00       406\n",
      "\n",
      "    accuracy                           0.95      7865\n",
      "   macro avg       0.47      0.50      0.49      7865\n",
      "weighted avg       0.90      0.95      0.92      7865\n",
      "\n",
      "\n",
      "direct_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89      6304\n",
      "           1       0.00      0.00      0.00      1561\n",
      "\n",
      "    accuracy                           0.80      7865\n",
      "   macro avg       0.40      0.50      0.44      7865\n",
      "weighted avg       0.64      0.80      0.71      7865\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see scores for the model\n",
    "print('OVERALL F-SCORES: ')\n",
    "print('Micro F1 Score: ' + str(f1_score(y_test2, Y_pred_sgd_grid, average = 'micro')))\n",
    "print('Macro F1 Score: ' + str(f1_score(y_test2, Y_pred_sgd_grid, average = 'macro')))\n",
    "print('Weighted F1 Score: ' + str(f1_score(y_test2, Y_pred_sgd_grid, average = 'weighted')))\n",
    "print('Samples F1 Score: ' + str(f1_score(y_test2, Y_pred_sgd_grid, average = 'samples')))\n",
    "\n",
    "column_list = list(Y.columns)\n",
    "for i in column_list:\n",
    "    y_true = y_test2.to_numpy()[:,column_list.index(i)]\n",
    "    y_pred = Y_pred_sgd_grid[:,column_list.index(i)]\n",
    "    print(column_list[column_list.index(i)]+ ':')\n",
    "    #text = [column_list[i], 'not']\n",
    "    print(classification_report(y_true, y_pred) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to model comparison dataframe\n",
    "models = models.append({'Model': 'SGD w/GridSearchCV', \n",
    "               'F1 Score (Micro)' : f1_score(y_test2, Y_pred_sgd_grid, average = 'micro'),\n",
    "               'F1 Score (Weighted)' : f1_score(y_test2, Y_pred_sgd_grid, average = 'weighted'),\n",
    "               'Training Time (Seconds)' : (stop-start)\n",
    "              }, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SGD model using GridSearchCV did not perform as well as the RandomForest using GridSearchCV.\n",
    "\n",
    "Due to requirement of project to implement a model that uses GridSearchCV, the model that uses Random Forest and GridSearchCV will be exported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(random_forest_v2, open('classifier.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
